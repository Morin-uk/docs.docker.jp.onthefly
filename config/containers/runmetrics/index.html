<!-- Page generated 2019-06-20 10:48:14 +0900 -->
<!-- relative link basehrefs -->

	
	
	
		
			
		
	
		
			
		
	
		
			
			


<!-- Logic for 'edit this button' -->


	

	

	

	

	

	

	

	

	


<!-- End of logic for 'edit this button' -->


<!DOCTYPE html>
<html lang="ja">

<head>
	<base href="https://matsuand.github.io/docs.docker.jp.onthefly/config/containers/" />
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<style type="text/css">
		@charset "UTF-8";
		[ng\:cloak],
		[ng-cloak],
		[data-ng-cloak],
		[x-ng-cloak],
		.ng-cloak,
		.x-ng-cloak,
		.ng-hide:not(.ng-hide-animate) {
			display: none !important;
		}

		ng\:form {
			display: block;
		}
	</style>
	<script type="text/javascript">
	  !function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="4.0.0";
	  analytics.load("IWj9D0UpZHZdZUZX9jl98PcpBFWBnBMy");
	  analytics.page();
	  }}();
	</script>
	
	<!-- favicon -->
	<link rel="icon" type="image/x-icon" href="https://matsuand.github.io/docs.docker.jp.onthefly/favicons/docs@2x.ico" sizes="129x128">
	<meta name="msapplication-TileImage" content="https://matsuand.github.io/docs.docker.jp.onthefly/favicons/docs@2x.ico">
	<link rel="apple-touch-icon" type="image/x-icon" href="https://matsuand.github.io/docs.docker.jp.onthefly/favicons/docs@2x.ico" sizes="129x128">
	<meta property="og:image" content="https://matsuand.github.io/docs.docker.jp.onthefly/favicons/docs@2x.ico"/>
	<!-- metadata -->
	<meta property="og:type" content="website"/>
	<meta property="og:updated_time" itemprop="dateUpdated" content="2019-06-20T10:48:14+09:00"/>
	<meta property="og:image" itemprop="image primaryImageOfPage" content="https://matsuand.github.io/docs.docker.jp.onthefly/images/docs@2x.png"/>
	<meta name="twitter:card" content="summary"/>
	<meta name="twitter:domain" content="docs.docker.jp"/>
	<meta name="twitter:site" content="@docker_docs"/>
	<meta name="twitter:url" content="https://twitter.com/docker_docs"/>
	<meta name="twitter:title" itemprop="title name" content="Runtime metrics"/>
	<meta name="twitter:description" property="og:description" itemprop="description" content="Docker stats You can use the docker stats command to live stream a container’s runtime metrics. The command supports CPU, memory usage, memory limit, and network IO metrics. The following..." />
	<meta name="twitter:image:src" content="https://matsuand.github.io/docs.docker.jp.onthefly/images/docs@2x.png"/>
	<meta name="twitter:image:alt" content="Docker Documentation"/>
	<meta property="article:published_time" itemprop="datePublished" content="2019-06-20T10:48:14+09:00"/>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="keywords" content="docker, metrics, CPU, memory, disk, IO, run, runtime, stats">
	<link rel="stylesheet" href="https://matsuand.github.io/docs.docker.jp.onthefly/css/font-awesome.min.css">
	<link rel="stylesheet" href="https://matsuand.github.io/docs.docker.jp.onthefly/css/bootstrap.min.css">
	<link id="pygments" rel="stylesheet" href="https://matsuand.github.io/docs.docker.jp.onthefly/css/pygments/perldoc.css">
	<link id="pagestyle" rel="stylesheet" href="https://matsuand.github.io/docs.docker.jp.onthefly/css/style.css">

	<!-- Go get "Open Sans" font from Google -->
	<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
	<!-- SEO stuff -->
	<title>Runtime metrics | Docker Documentation</title>
<meta property="og:title" content="Runtime metrics" />
<meta property="og:locale" content="ja_JP" />
<meta name="description" content="Measure the behavior of running containers" />
<meta property="og:description" content="Measure the behavior of running containers" />
<link rel="canonical" href="https://matsuand.github.io/docs.docker.jp.onthefly/config/containers/runmetrics/" />
<meta property="og:url" content="https://matsuand.github.io/docs.docker.jp.onthefly/config/containers/runmetrics/" />
<meta property="og:site_name" content="Docker Documentation" />
<script type="application/ld+json">
{"@context":"http://schema.org","@type":"WebPage","headline":"Runtime metrics","description":"Measure the behavior of running containers","url":"https://matsuand.github.io/docs.docker.jp.onthefly/config/containers/runmetrics/"}</script>
	<!-- END SEO STUFF -->
	
	<script language="javascript">
	// Default to assuming this is an archive and hiding some stuff
	// See js/archive.js and js/docs.js for logic relating to this
	var isArchive = true;
	var dockerVersion = 'v18.09';
	</script>
</head>
<body ng-app="Docker" ng-controller="DockerController" class="colums">
	<header>
		 <nav class="nav-secondary navbar navbar-fixed-top">
    <!-- <div class="fan"></div> -->
    <div class="container-fluid">
        <div class="navbar-header">
            <a href="https://matsuand.github.io/docs.docker.jp.onthefly/"><img class="logo" src="https://matsuand.github.io/docs.docker.jp.onthefly/images/docker-docs-logo.svg" alt="Docker Docs" title="Docker Docs"></a>
        </div>
        <div class="navbar-collapse" aria-expanded="false" style="height: 1px;">
            <div class="search-form" id="search-div" style="visibility: hidden">
    <form class="search-form form-inline ng-pristine ng-valid" id="searchForm" action="https://matsuand.github.io/docs.docker.jp.onthefly/search/">
        <input class="search-field form-control ds-input" id="st-search-input" value="" name="q" placeholder="文書内検索" type="search" autocomplete="off" spellcheck="false" dir="auto" style="position: relative; vertical-align: top;">
        <div id="autocompleteContainer">
            <div id="autocompleteResults"></div>
        </div>
        <!-- <button type="submit" class="search-submit btn btn-default">検索</button> -->
    </form>
</div>
<div class="sidebar-toggle">
    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
    </button>
</div>
<div class="nav-container">
    <div id="tabs">
        <ul class="tabs" id="jsTOCHorizontal">

        </ul>
    </div>
    <div class="ctrl-right hidden-xs hidden-sm">
        <a href="javascript:void(0)" id="menu-toggle"><i class="fa fa-indent" aria-hidden="true"></i></a>
        <div class="btn-group" style="visibility: hidden">
  <button type="button" class="btn btn-default dropdown-btn dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
    Docker v18.09 (current)        <span class="caret"></span>
  </button>
  <ul class="dropdown-menu">
    <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/edge/">Docker edge</a></li><li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/v18.03/">Docker v18.03</a></li><li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/v17.12/">Docker v17.12</a></li><li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/v17.09/">Docker v17.09</a></li><li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/v17.06/">Docker v17.06</a></li><li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/v17.03/">Docker v17.03</a></li>
  </ul>
</div>

    </div>
</div>

        </div>
    </div>
</nav>

	</header>

	<div class="wrapper right-open">
		<div class="container-fluid">
			<div class="row">
				<div class="col-body">
					<main class="col-content content">
						<section class="section">
							
								
							<h1>Runtime metrics</h1>  <span class="reading-time" title="Estimated reading time">
  <span class="reading-time-label">読む時間の目安: </span>
  
  
    17 分
  
</span>

							
							
							<h2 id="docker-stats">Docker stats</h2>

<p>You can use the <code class="highlighter-rouge">docker stats</code> command to live stream a container’s
runtime metrics. The command supports CPU, memory usage, memory limit,
and network IO metrics.</p>

<p>The following is a sample output from the <code class="highlighter-rouge">docker stats</code> command</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stats redis1 redis2

CONTAINER           CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O
redis1              0.07%               796 KB / 64 MB        1.21%               788 B / 648 B       3.568 MB / 512 KB
redis2              0.07%               2.746 MB / 64 MB      4.29%               1.266 KB / 648 B    12.4 MB / 0 B
</code></pre></div></div>

<p>The <a href="https://matsuand.github.io/docs.docker.jp.onthefly/engine/reference/commandline/stats.md">docker stats</a> reference page has
more details about the <code class="highlighter-rouge">docker stats</code> command.</p>

<h2 id="control-groups">Control groups</h2>

<p>Linux Containers rely on <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">control groups</a>
which not only track groups of processes, but also expose metrics about
CPU, memory, and block I/O usage. You can access those metrics and
obtain network usage metrics as well. This is relevant for “pure” LXC
containers, as well as for Docker containers.</p>

<p>Control groups are exposed through a pseudo-filesystem. In recent
distros, you should find this filesystem under <code class="highlighter-rouge">/sys/fs/cgroup</code>. Under
that directory, you see multiple sub-directories, called devices,
freezer, blkio, etc.; each sub-directory actually corresponds to a different
cgroup hierarchy.</p>

<p>On older systems, the control groups might be mounted on <code class="highlighter-rouge">/cgroup</code>, without
distinct hierarchies. In that case, instead of seeing the sub-directories,
you see a bunch of files in that directory, and possibly some directories
corresponding to existing containers.</p>

<p>To figure out where your control groups are mounted, you can run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">grep </span>cgroup /proc/mounts
</code></pre></div></div>

<h3 id="enumerate-cgroups">Enumerate cgroups</h3>

<p>You can look into <code class="highlighter-rouge">/proc/cgroups</code> to see the different control group subsystems
known to the system, the hierarchy they belong to, and how many groups they contain.</p>

<p>You can also look at <code class="highlighter-rouge">/proc/&lt;pid&gt;/cgroup</code> to see which control groups a process
belongs to. The control group is shown as a path relative to the root of
the hierarchy mountpoint. <code class="highlighter-rouge">/</code> means the process has not been assigned to a
group, while <code class="highlighter-rouge">/lxc/pumpkin</code> indicates that the process is a member of a
container named <code class="highlighter-rouge">pumpkin</code>.</p>

<h3 id="find-the-cgroup-for-a-given-container">Find the cgroup for a given container</h3>

<p>For each container, one cgroup is created in each hierarchy. On
older systems with older versions of the LXC userland tools, the name of
the cgroup is the name of the container. With more recent versions
of the LXC tools, the cgroup is <code class="highlighter-rouge">lxc/&lt;container_name&gt;.</code></p>

<p>For Docker containers using cgroups, the container name is the full
ID or long ID of the container. If a container shows up as ae836c95b4c3
in <code class="highlighter-rouge">docker ps</code>, its long ID might be something like
<code class="highlighter-rouge">ae836c95b4c3c9e9179e0e91015512da89fdec91612f63cebae57df9a5444c79</code>. You can
look it up with <code class="highlighter-rouge">docker inspect</code> or <code class="highlighter-rouge">docker ps --no-trunc</code>.</p>

<p>Putting everything together to look at the memory metrics for a Docker
container, take a look at <code class="highlighter-rouge">/sys/fs/cgroup/memory/docker/&lt;longid&gt;/</code>.</p>

<h3 id="metrics-from-cgroups-memory-cpu-block-io">Metrics from cgroups: memory, CPU, block I/O</h3>

<p>For each subsystem (memory, CPU, and block I/O), one or
more pseudo-files exist and contain statistics.</p>

<h4 id="memory-metrics-memorystat">Memory metrics: <code class="highlighter-rouge">memory.stat</code></h4>

<p>Memory metrics are found in the “memory” cgroup. The memory
control group adds a little overhead, because it does very fine-grained
accounting of the memory usage on your host. Therefore, many distros
chose to not enable it by default. Generally, to enable it, all you have
to do is to add some kernel command-line parameters:
<code class="highlighter-rouge">cgroup_enable=memory swapaccount=1</code>.</p>

<p>The metrics are in the pseudo-file <code class="highlighter-rouge">memory.stat</code>.
Here is what it looks like:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cache 11492564992
rss 1930993664
mapped_file 306728960
pgpgin 406632648
pgpgout 403355412
swap 0
pgfault 728281223
pgmajfault 1724
inactive_anon 46608384
active_anon 1884520448
inactive_file 7003344896
active_file 4489052160
unevictable 32768
hierarchical_memory_limit 9223372036854775807
hierarchical_memsw_limit 9223372036854775807
total_cache 11492564992
total_rss 1930993664
total_mapped_file 306728960
total_pgpgin 406632648
total_pgpgout 403355412
total_swap 0
total_pgfault 728281223
total_pgmajfault 1724
total_inactive_anon 46608384
total_active_anon 1884520448
total_inactive_file 7003344896
total_active_file 4489052160
total_unevictable 32768
</code></pre></div></div>

<p>The first half (without the <code class="highlighter-rouge">total_</code> prefix) contains statistics relevant
to the processes within the cgroup, excluding sub-cgroups. The second half
(with the <code class="highlighter-rouge">total_</code> prefix) includes sub-cgroups as well.</p>

<p>Some metrics are “gauges”, or values that can increase or decrease. For instance,
<code class="highlighter-rouge">swap</code> is the amount of swap space used by the members of the cgroup.
Some others are “counters”, or values that can only go up, because
they represent occurrences of a specific event. For instance, <code class="highlighter-rouge">pgfault</code>
indicates the number of page faults since the creation of the cgroup.</p>

<style>table tr > td:first-child { white-space: nowrap;}</style>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>cache</strong></td>
      <td>The amount of memory used by the processes of this control group that can be associated precisely with a block on a block device. When you read from and write to files on disk, this amount increases. This is the case if you use “conventional” I/O (<code class="highlighter-rouge">open</code>, <code class="highlighter-rouge">read</code>, <code class="highlighter-rouge">write</code> syscalls) as well as mapped files (with <code class="highlighter-rouge">mmap</code>). It also accounts for the memory used by <code class="highlighter-rouge">tmpfs</code> mounts, though the reasons are unclear.</td>
    </tr>
    <tr>
      <td><strong>rss</strong></td>
      <td>The amount of memory that <em>doesn’t</em> correspond to anything on disk: stacks, heaps, and anonymous memory maps.</td>
    </tr>
    <tr>
      <td><strong>mapped_file</strong></td>
      <td>Indicates the amount of memory mapped by the processes in the control group. It doesn’t give you information about <em>how much</em> memory is used; it rather tells you <em>how</em> it is used.</td>
    </tr>
    <tr>
      <td><strong>pgfault</strong>, <strong>pgmajfault</strong></td>
      <td>Indicate the number of times that a process of the cgroup triggered a “page fault” and a “major fault”, respectively. A page fault happens when a process accesses a part of its virtual memory space which is nonexistent or protected. The former can happen if the process is buggy and tries to access an invalid address (it is sent a <code class="highlighter-rouge">SIGSEGV</code> signal, typically killing it with the famous <code class="highlighter-rouge">Segmentation fault</code> message). The latter can happen when the process reads from a memory zone which has been swapped out, or which corresponds to a mapped file: in that case, the kernel loads the page from disk, and let the CPU complete the memory access. It can also happen when the process writes to a copy-on-write memory zone: likewise, the kernel preempts the process, duplicate the memory page, and resume the write operation on the process` own copy of the page. “Major” faults happen when the kernel actually needs to read the data from disk. When it just  duplicates an existing page, or allocate an empty page, it’s a regular (or “minor”) fault.</td>
    </tr>
    <tr>
      <td><strong>swap</strong></td>
      <td>The amount of swap currently used by the processes in this cgroup.</td>
    </tr>
    <tr>
      <td><strong>active_anon</strong>, <strong>inactive_anon</strong></td>
      <td>The amount of <em>anonymous</em> memory that has been identified has respectively <em>active</em> and <em>inactive</em> by the kernel. “Anonymous” memory is the memory that is <em>not</em> linked to disk pages. In other words, that’s the equivalent of the rss counter described above. In fact, the very definition of the rss counter is <strong>active_anon</strong> + <strong>inactive_anon</strong> - <strong>tmpfs</strong> (where tmpfs is the amount of memory used up by <code class="highlighter-rouge">tmpfs</code> filesystems mounted by this control group). Now, what’s the difference between “active” and “inactive”? Pages are initially “active”; and at regular intervals, the kernel sweeps over the memory, and tags some pages as “inactive”. Whenever they are accessed again, they are immediately retagged “active”. When the kernel is almost out of memory, and time comes to swap out to disk, the kernel swaps “inactive” pages.</td>
    </tr>
    <tr>
      <td><strong>active_file</strong>, <strong>inactive_file</strong></td>
      <td>Cache memory, with <em>active</em> and <em>inactive</em> similar to the <em>anon</em> memory above. The exact formula is <strong>cache</strong> = <strong>active_file</strong> + <strong>inactive_file</strong> + <strong>tmpfs</strong>. The exact rules used by the kernel to move memory pages between active and inactive sets are different from the ones used for anonymous memory, but the general principle is the same. When the kernel needs to reclaim memory, it is cheaper to reclaim a clean (=non modified) page from this pool, since it can be reclaimed immediately (while anonymous pages and dirty/modified pages need to be written to disk first).</td>
    </tr>
    <tr>
      <td><strong>unevictable</strong></td>
      <td>The amount of memory that cannot be reclaimed; generally, it accounts for memory that has been “locked” with <code class="highlighter-rouge">mlock</code>. It is often used by crypto frameworks to make sure that secret keys and other sensitive material never gets swapped out to disk.</td>
    </tr>
    <tr>
      <td><strong>memory_limit</strong>, <strong>memsw_limit</strong></td>
      <td>These are not really metrics, but a reminder of the limits applied to this cgroup. The first one indicates the maximum amount of physical memory that can be used by the processes of this control group; the second one indicates the maximum amount of RAM+swap.</td>
    </tr>
  </tbody>
</table>

<p>Accounting for memory in the page cache is very complex. If two
processes in different control groups both read the same file
(ultimately relying on the same blocks on disk), the corresponding
memory charge is split between the control groups. It’s nice, but
it also means that when a cgroup is terminated, it could increase the
memory usage of another cgroup, because they are not splitting the cost
anymore for those memory pages.</p>

<h3 id="cpu-metrics-cpuacctstat">CPU metrics: <code class="highlighter-rouge">cpuacct.stat</code></h3>

<p>Now that we’ve covered memory metrics, everything else is
simple in comparison. CPU metrics are in the
<code class="highlighter-rouge">cpuacct</code> controller.</p>

<p>For each container, a pseudo-file <code class="highlighter-rouge">cpuacct.stat</code> contains the CPU usage
accumulated by the processes of the container, broken down into <code class="highlighter-rouge">user</code> and
<code class="highlighter-rouge">system</code> time. The distinction is:</p>

<ul>
  <li><code class="highlighter-rouge">user</code> time is the amount of time a process has direct control of the CPU,
executing process code.</li>
  <li><code class="highlighter-rouge">system</code> time is the time the kernel is executing system calls on behalf of
the process.</li>
</ul>

<p>Those times are expressed in ticks of 1/100th of a second, also called “user
jiffies”. There are <code class="highlighter-rouge">USER_HZ</code> <em>“jiffies”</em> per second, and on x86 systems,
<code class="highlighter-rouge">USER_HZ</code> is 100. Historically, this mapped exactly to the number of scheduler
“ticks” per second, but higher frequency scheduling and
<a href="http://lwn.net/Articles/549580/">tickless kernels</a> have made the number of
ticks irrelevant.</p>

<h4 id="block-io-metrics">Block I/O metrics</h4>

<p>Block I/O is accounted in the <code class="highlighter-rouge">blkio</code> controller.
Different metrics are scattered across different files. While you can
find in-depth details in the <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/blkio-controller.txt">blkio-controller</a>
file in the kernel documentation, here is a short list of the most
relevant ones:</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>blkio.sectors</strong></td>
      <td>Contains the number of 512-bytes sectors read and written by the processes member of the cgroup, device by device. Reads and writes are merged in a single counter.</td>
    </tr>
    <tr>
      <td><strong>blkio.io_service_bytes</strong></td>
      <td>Indicates the number of bytes read and written by the cgroup. It has 4 counters per device, because for each device, it differentiates between synchronous vs. asynchronous I/O, and reads vs. writes.</td>
    </tr>
    <tr>
      <td><strong>blkio.io_serviced</strong></td>
      <td>The number of I/O operations performed, regardless of their size. It also has 4 counters per device.</td>
    </tr>
    <tr>
      <td><strong>blkio.io_queued</strong></td>
      <td>Indicates the number of I/O operations currently queued for this cgroup. In other words, if the cgroup isn’t doing any I/O, this is zero. The opposite is not true. In other words, if there is no I/O queued, it does not mean that the cgroup is idle (I/O-wise). It could be doing purely synchronous reads on an otherwise quiescent device, which can therefore handle them immediately, without queuing. Also, while it is helpful to figure out which cgroup is putting stress on the I/O subsystem, keep in mind that it is a relative quantity. Even if a process group does not perform more I/O, its queue size can increase just because the device load increases because of other devices.</td>
    </tr>
  </tbody>
</table>

<h3 id="network-metrics">Network metrics</h3>

<p>Network metrics are not exposed directly by control groups. There is a
good explanation for that: network interfaces exist within the context
of <em>network namespaces</em>. The kernel could probably accumulate metrics
about packets and bytes sent and received by a group of processes, but
those metrics wouldn’t be very useful. You want per-interface metrics
(because traffic happening on the local <code class="highlighter-rouge">lo</code>
interface doesn’t really count). But since processes in a single cgroup
can belong to multiple network namespaces, those metrics would be harder
to interpret: multiple network namespaces means multiple <code class="highlighter-rouge">lo</code>
interfaces, potentially multiple <code class="highlighter-rouge">eth0</code>
interfaces, etc.; so this is why there is no easy way to gather network
metrics with control groups.</p>

<p>Instead we can gather network metrics from other sources:</p>

<h4 id="iptables">IPtables</h4>

<p>IPtables (or rather, the netfilter framework for which iptables is just
an interface) can do some serious accounting.</p>

<p>For instance, you can setup a rule to account for the outbound HTTP
traffic on a web server:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>iptables <span class="nt">-I</span> OUTPUT <span class="nt">-p</span> tcp <span class="nt">--sport</span> 80
</code></pre></div></div>

<p>There is no <code class="highlighter-rouge">-j</code> or <code class="highlighter-rouge">-g</code> flag,
so the rule just counts matched packets and goes to the following
rule.</p>

<p>Later, you can check the values of the counters, with:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>iptables <span class="nt">-nxvL</span> OUTPUT
</code></pre></div></div>

<p>Technically, <code class="highlighter-rouge">-n</code> is not required, but it
prevents iptables from doing DNS reverse lookups, which are probably
useless in this scenario.</p>

<p>Counters include packets and bytes. If you want to setup metrics for
container traffic like this, you could execute a <code class="highlighter-rouge">for</code>
loop to add two <code class="highlighter-rouge">iptables</code> rules per
container IP address (one in each direction), in the <code class="highlighter-rouge">FORWARD</code>
chain. This only meters traffic going through the NAT
layer; you also need to add traffic going through the userland
proxy.</p>

<p>Then, you need to check those counters on a regular basis. If you
happen to use <code class="highlighter-rouge">collectd</code>, there is a <a href="https://collectd.org/wiki/index.php/Table_of_Plugins">nice plugin</a>
to automate iptables counters collection.</p>

<h4 id="interface-level-counters">Interface-level counters</h4>

<p>Since each container has a virtual Ethernet interface, you might want to check
directly the TX and RX counters of this interface. Each container is associated
to a virtual Ethernet interface in your host, with a name like <code class="highlighter-rouge">vethKk8Zqi</code>.
Figuring out which interface corresponds to which container is, unfortunately,
difficult.</p>

<p>But for now, the best way is to check the metrics <em>from within the
containers</em>. To accomplish this, you can run an executable from the host
environment within the network namespace of a container using <strong>ip-netns
magic</strong>.</p>

<p>The <code class="highlighter-rouge">ip-netns exec</code> command allows you to execute any
program (present in the host system) within any network namespace
visible to the current process. This means that your host can
 enter the network namespace of your containers, but your containers
can’t access the host or other peer containers.
Containers can interact with their sub-containers, though.</p>

<p>The exact format of the command is:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ip netns <span class="nb">exec</span> &lt;nsname&gt; &lt;command...&gt;
</code></pre></div></div>

<p>For example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ip netns <span class="nb">exec </span>mycontainer netstat <span class="nt">-i</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">ip netns</code> finds the “mycontainer” container by
using namespaces pseudo-files. Each process belongs to one network
namespace, one PID namespace, one <code class="highlighter-rouge">mnt</code> namespace,
etc., and those namespaces are materialized under
<code class="highlighter-rouge">/proc/&lt;pid&gt;/ns/</code>. For example, the network
namespace of PID 42 is materialized by the pseudo-file
<code class="highlighter-rouge">/proc/42/ns/net</code>.</p>

<p>When you run <code class="highlighter-rouge">ip netns exec mycontainer ...</code>, it
expects <code class="highlighter-rouge">/var/run/netns/mycontainer</code> to be one of
those pseudo-files. (Symlinks are accepted.)</p>

<p>In other words, to execute a command within the network namespace of a
container, we need to:</p>

<ul>
  <li>Find out the PID of any process within the container that we want to investigate;</li>
  <li>Create a symlink from <code class="highlighter-rouge">/var/run/netns/&lt;somename&gt;</code> to <code class="highlighter-rouge">/proc/&lt;thepid&gt;/ns/net</code></li>
  <li>Execute <code class="highlighter-rouge">ip netns exec &lt;somename&gt; ....</code></li>
</ul>

<p>Review <a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#enumerate-cgroups">Enumerate Cgroups</a> for how to find
the cgroup of an in-container process whose network usage you want to measure.
From there, you can examine the pseudo-file named
<code class="highlighter-rouge">tasks</code>, which contains all the PIDs in the
cgroup (and thus, in the container). Pick any one of the PIDs.</p>

<p>Putting everything together, if the “short ID” of a container is held in
the environment variable <code class="highlighter-rouge">$CID</code>, then you can do this:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ TASKS</span><span class="o">=</span>/sys/fs/cgroup/devices/docker/<span class="nv">$CID</span><span class="k">*</span>/tasks
<span class="nv">$ PID</span><span class="o">=</span><span class="k">$(</span>head <span class="nt">-n</span> 1 <span class="nv">$TASKS</span><span class="k">)</span>
<span class="nv">$ </span>mkdir <span class="nt">-p</span> /var/run/netns
<span class="nv">$ </span>ln <span class="nt">-sf</span> /proc/<span class="nv">$PID</span>/ns/net /var/run/netns/<span class="nv">$CID</span>
<span class="nv">$ </span>ip netns <span class="nb">exec</span> <span class="nv">$CID</span> netstat <span class="nt">-i</span>
</code></pre></div></div>

<h2 id="tips-for-high-performance-metric-collection">Tips for high-performance metric collection</h2>

<p>Running a new process each time you want to update metrics is
(relatively) expensive. If you want to collect metrics at high
resolutions, and/or over a large number of containers (think 1000
containers on a single host), you do not want to fork a new process each
time.</p>

<p>Here is how to collect metrics from a single process. You need to
write your metric collector in C (or any language that lets you do
low-level system calls). You need to use a special system call,
<code class="highlighter-rouge">setns()</code>, which lets the current process enter any
arbitrary namespace. It requires, however, an open file descriptor to
the namespace pseudo-file (remember: that’s the pseudo-file in
<code class="highlighter-rouge">/proc/&lt;pid&gt;/ns/net</code>).</p>

<p>However, there is a catch: you must not keep this file descriptor open.
If you do, when the last process of the control group exits, the
namespace is not destroyed, and its network resources (like the
virtual interface of the container) stays around forever (or until
you close that file descriptor).</p>

<p>The right approach would be to keep track of the first PID of each
container, and re-open the namespace pseudo-file each time.</p>

<h2 id="collect-metrics-when-a-container-exits">Collect metrics when a container exits</h2>

<p>Sometimes, you do not care about real time metric collection, but when a
container exits, you want to know how much CPU, memory, etc. it has
used.</p>

<p>Docker makes this difficult because it relies on <code class="highlighter-rouge">lxc-start</code>, which carefully
cleans up after itself. It is usually easier to collect metrics at regular
intervals, and this is the way the <code class="highlighter-rouge">collectd</code> LXC plugin works.</p>

<p>But, if you’d still like to gather the stats when a container stops,
here is how:</p>

<p>For each container, start a collection process, and move it to the
control groups that you want to monitor by writing its PID to the tasks
file of the cgroup. The collection process should periodically re-read
the tasks file to check if it’s the last process of the control group.
(If you also want to collect network statistics as explained in the
previous section, you should also move the process to the appropriate
network namespace.)</p>

<p>When the container exits, <code class="highlighter-rouge">lxc-start</code> attempts to
delete the control groups. It fails, since the control group is
still in use; but that’s fine. Your process should now detect that it is
the only one remaining in the group. Now is the right time to collect
all the metrics you need!</p>

<p>Finally, your process should move itself back to the root control group,
and remove the container control group. To remove a control group, just
<code class="highlighter-rouge">rmdir</code> its directory. It’s counter-intuitive to
<code class="highlighter-rouge">rmdir</code> a directory as it still contains files; but
remember that this is a pseudo-filesystem, so usual rules don’t apply.
After the cleanup is done, the collection process can exit safely.</p>

							<!-- tags -->
							
							
							
							<span class="glyphicon glyphicon-tags" style="padding-right: 10px"></span><span style="vertical-align: 2px"><a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=docker">docker</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=metrics">metrics</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=CPU">CPU</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=memory">memory</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=disk">disk</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=IO">IO</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=run">run</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=runtime">runtime</a>, <a href="https://matsuand.github.io/docs.docker.jp.onthefly/glossary/?term=stats">stats</a></span>
							
							<!-- link corrections -->
              <script language="JavaScript">
							var x = document.links.length;
							var baseHref = document.getElementsByTagName('base')[0].href
							for (i = 0; i < x; i++) {
							  var munged = false;
							  var thisHREF = document.links[i].href;
							  var originalURL = "/config/containers/runmetrics/";
							  if (thisHREF.indexOf(baseHref + "#") > -1) {
							    // hash fix
							    //console.log('BEFORE: base:',baseHref,'thisHREF:',thisHREF,'originalURL:',originalURL);
							    thisHREF = originalURL + thisHREF.replace(baseHref, "");
							    //console.log('AFTER: base:',baseHref,'thisHREF:',thisHREF,'originalURL:',originalURL);
							  }
							  if ((thisHREF.indexOf(window.location.hostname) > -1 || thisHREF.indexOf('http') == -1) && document.links[i].className.indexOf("nomunge") < 0) {
							    munged = true;
							    thisHREF = thisHREF.replace(".md", "/").replace("/index/", "/");
							    document.links[i].setAttribute('href', thisHREF);
							  }
							}
							</script>
							
						  <div id="ratings-div" style="color:#b9c2cc; text-align: center; margin-top: 150px; visibility: hidden">
								<div id="pd_rating_holder_8453675"></div>
								<script type="text/javascript">
									PDRTJS_settings_8453675 = {
										"id": "8453675",
										"unique_id": "config/containers/runmetrics.md",
										"title": "Runtime metrics",
										"permalink": "https://github.com/docker/docker.github.io/blob/master/config/containers/runmetrics.md"
									};
									(function(d, c, j) {
										if (!document.getElementById(j)) {
											var pd = d.createElement(c),
												s;
											pd.id = j;
											pd.src = ('https:' == document.location.protocol) ? 'https://polldaddy.com/js/rating/rating.js' : 'http://i0.poll.fm/js/rating/rating.js';
											s = document.getElementsByTagName(c)[0];
											s.parentNode.insertBefore(pd, s);
										}
									}(document, 'script', 'pd-rating-js'));
								</script>
							</div>
							
						</section>
					</main>
					<nav class="col-nav">
						<div id="sidebar-nav" class="sidebar hidden-sm hidden-xs">
						<div id="navbar" class="nav-sidebar">
    <ul class="nav" id="jsTOCLeftNav">
    </ul>
</div>

						</div>
					</nav>
					<div class="col-toc">
							<div class="sidebar hidden-xs hidden-sm">
							<div class="toc-nav">
								<div class="feedback-links">
									<ul>
										
										<li style="visibility: hidden"><a href="https://github.com/matsuand/docs.docker.jp/edit/v18.09.local/config/containers/runmetrics.md"><i class="fa fa-pencil-square-o" aria-hidden="true"></i> このページの編集</a></li>
										<li><a href="https://github.com/matsuand/docs.docker.jp.onthefly/issues/new?body=File: [config/containers/runmetrics.md](https://matsuand.github.io/docs.docker.jp.onthefly/config/containers/runmetrics/)"
															class="nomunge"><i class="fa fa-check" aria-hidden="true"></i> 文書変更のリクエスト</a></li>
										<li><a href="https://success.docker.com/support"><i class="fa fa-question" aria-hidden="true"></i> サポート依頼</a></li>
										<!-- toggle mode -->
										<li>
											<div class="toggle-mode">
												<div class="icon">
													<i class="fa fa-sun-o" aria-hidden="true"></i>
												</div>
												<div class="toggle-switch">
													<label class="switch">
														<input type="checkbox" id="switch-style">
														<div class="slider round"></div>
												</label>
												</div>
												<div class="icon">
													<i class="fa fa-moon-o" aria-hidden="true"></i>
												</div>
											</div>
										</li>
									</ul>
								</div>
								   
									<div id="side-toc-title">本ページ内</div>
									
<ul id="my_toc" class="inline_toc">
  <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#docker-stats" class="nomunge">Docker stats</a></li>
  <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#control-groups" class="nomunge">Control groups</a>
    <ul>
      <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#enumerate-cgroups" class="nomunge">Enumerate cgroups</a></li>
      <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#find-the-cgroup-for-a-given-container" class="nomunge">Find the cgroup for a given container</a></li>
      <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#metrics-from-cgroups-memory-cpu-block-io" class="nomunge">Metrics from cgroups: memory, CPU, block I/O</a></li>
      <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#cpu-metrics-cpuacctstat" class="nomunge">CPU metrics: cpuacct.stat</a></li>
      <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#network-metrics" class="nomunge">Network metrics</a></li>
    </ul>
  </li>
  <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#tips-for-high-performance-metric-collection" class="nomunge">Tips for high-performance metric collection</a></li>
  <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/runmetrics.md#collect-metrics-when-a-container-exits" class="nomunge">Collect metrics when a container exits</a></li>
</ul>


								</div>
								
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>

	
	<footer class="footer">
		  
    <div class="container">
        <div class="top_footer">
            <div class="row">
                <div class="col-xs-12 col-sm-3 col-md-3">
                    <ul class="footer_links">
                        <li><a href="https://www.docker.com/what-docker">What is Docker</a></li>
                        <li><a href="https://www.docker.com/what-container">What is a Container</a></li>
                        <li><a href="https://www.docker.com/use-cases">Use Cases</a></li>
                        <li><a href="https://www.docker.com/customers">Customers</a></li>
                        <li><a href="https://www.docker.com/partners/partner-program">Partners</a></li>
                        <li class="break"><a href="https://www.docker.com/industry-government">For Government</a></li>
                        <li><a href="https://www.docker.com/company">About Docker</a></li>
                        <li><a href="https://www.docker.com/company/management">Management</a></li>
                        <li><a href="https://www.docker.com/company/news-and-press">Press &amp; News</a></li>
                        <li><a href="https://www.docker.com/careers">Careers</a></li>
                    </ul>
                </div>
                <div class="col-xs-12 col-sm-3 col-md-3">
                    <ul class="footer_links">
                        <li><a href="https://www.docker.com/products/overview">Product</a></li>
                        <li><a href="https://www.docker.com/pricing">Pricing</a></li>
                        <li><a href="https://www.docker.com/docker-community">Community Edition</a></li>
                        <li class="break"><a href="https://www.docker.com/enterprise">Enterprise Edition </a></li>
                        <li><a href="https://www.docker.com/products/docker-datacenter">Docker Datacenter</a></li>
                        <li><a href="https://hub.docker.com/">Docker Hub</a></li>
                    </ul>
                </div>
                <div class="col-xs-12 col-sm-3 col-md-3">
                    <ul class="footer_links">
                        <li><a href="https://matsuand.github.io/docs.docker.jp.onthefly/">Documentation</a></li>
                        <li><a href="https://www.docker.com/docker">Learn</a></li>
                        <li><a href="https://blog.docker.com" target="_blank">Blog</a></li>
                        <li><a href="https://engineering.docker.com" target="_blank">Engineering Blog</a></li>
                        <li><a href="https://training.docker.com/" target="_blank">Training</a></li>
                        <li><a href="https://success.docker.com/support">Support</a></li>
                        <li><a href="https://success.docker.com/kbase">Knowledge Base</a></li>
                        <li><a href="https://www.docker.com/products/resources">Resources</a></li>
                    </ul>
                </div>
                <div class="col-xs-12 col-sm-3 col-md-3">
                    <ul class="footer_links">
                        <li><a href="https://www.docker.com/docker-community">Community</a></li>
                        <li><a href="https://www.docker.com/technologies/overview">Open Source</a></li>
                        <li><a href="https://www.docker.com/community/events">Events</a></li>
                        <li><a href="https://forums.docker.com/" target="_blank">Forums</a></li>
                        <li><a href="https://www.docker.com/community/docker-captains">Docker Captains</a></li>
                        <li><a href="https://www.docker.com/docker-community/scholarships">Scholarships</a></li>
                        <li><a href="https://blog.docker.com/curated/">Community News</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-nav">
                <nav class="footer_sub_nav">
                    <ul class="menu">
                        <li><a href="http://status.docker.com/">Status</a></li>
                        <li><a href="https://www.docker.com/docker-security">Security</a></li>
                        <li><a href="https://www.docker.com/legal">Legal</a></li>
                        <li><a href="https://www.docker.com/company/contact">Contact</a></li>
                    </ul>
                </nav>
            </div>
        </div>
        <div class="bottom_footer">
            <div class="footer-copyright col-xs-12 col-md-8">
                <p class="copyright">
                    Copyright &copy; 2019 Docker Inc. All rights reserved. </p>
            </div>
            <div class="footer_social_nav">
                <ul class="nav-social">
                    <li class="fa fa-twitter"><a href="http://twitter.com/docker">Twitter</a></li>
                    <li class="fa fa-youtube"><a href="http://www.youtube.com/user/dockerrun">Youtube</a></li>
                    <li class="fa fa-github"><a href="https://github.com/docker">GitHub</a></li>
                    <li class="fa fa-linkedin"><a href="https://www.linkedin.com/company/docker">Linkedin</a></li>
                    <li class="fa fa-facebook"><a href="https://www.facebook.com/docker.run">Facebook</a></li>
                    <li class="fa fa-reddit"><a href="http://www.reddit.com/r/docker">Reddit</a></li>
                    <li class="fa fa-slideshare"><a href="http://www.slideshare.net/docker">Slideshare</a></li>
                </ul>
            </div>
        </div>
    </div>

	</footer>
	<link rel="stylesheet" href="https://matsuand.github.io/docs.docker.jp.onthefly/css/github.css">
	
	<!-- <script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/anchorlinks.js"></script> -->
	<script defer src="https://matsuand.github.io/docs.docker.jp.onthefly/js/menu.js"></script>
	<script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/jquery.js"></script>
	<script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/bootstrap.min.js"></script>
	<!-- Always include the archive.js, but it doesn't do much unless we are an archive -->
	<script language="javascript">
	// Default to assuming this is an archive and hiding some stuff
	// See js/archive.js and js/docs.js for logic relating to this
	var isArchive = true;
	var dockerVersion = 'v18.09';
	// In archives, we need to know the page root and we get it from JEKYLL_ENV in the jekyll build command
	var jekyllEnv = 'development';
	// If unset (in non-archive branches), defaults to "development". In that case, reset it to empty
	if (jekyllEnv == 'development') {
		jekyllEnv = '';
	}
	var pageURL = jekyllEnv + '/config/containers/runmetrics/';
	</script>
	<script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/archive.js"></script>
	<script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/stickyfill.min.js"></script>
	<script defer src="https://matsuand.github.io/docs.docker.jp.onthefly/js/metadata.js"></script>
	<script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/glossary.js"></script>
	<script src="https://matsuand.github.io/docs.docker.jp.onthefly/js/collections_tocs.js"></script>
	<script defer src="https://matsuand.github.io/docs.docker.jp.onthefly/js/docs.js"></script>
	<script defer src="https://matsuand.github.io/docs.docker.jp.onthefly/js/toc.js"></script>
	<script language="javascript">
	jQuery(document).ready(function(){
				hookupTOCEvents();
			});
	</script>
</body>

</html>
